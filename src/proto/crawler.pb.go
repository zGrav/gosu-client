// Code generated by protoc-gen-go.
// source: crawler.proto
// DO NOT EDIT!

package gosuproto

import proto "github.com/golang/protobuf/proto"

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal

type CrawlerGetSiteInfoResponse_ErrorType int32

const (
	CrawlerGetSiteInfoResponse_NONE             CrawlerGetSiteInfoResponse_ErrorType = 0
	CrawlerGetSiteInfoResponse_BAD_REQUEST      CrawlerGetSiteInfoResponse_ErrorType = 1
	CrawlerGetSiteInfoResponse_FORBIDDEN        CrawlerGetSiteInfoResponse_ErrorType = 2
	CrawlerGetSiteInfoResponse_UNKNOWN_ERROR    CrawlerGetSiteInfoResponse_ErrorType = 3
	CrawlerGetSiteInfoResponse_PAGE_NOT_FOUND   CrawlerGetSiteInfoResponse_ErrorType = 4
	CrawlerGetSiteInfoResponse_COULD_NOT_DECODE CrawlerGetSiteInfoResponse_ErrorType = 5
	CrawlerGetSiteInfoResponse_COULD_NOT_CRAWL  CrawlerGetSiteInfoResponse_ErrorType = 6
)

var CrawlerGetSiteInfoResponse_ErrorType_name = map[int32]string{
	0: "NONE",
	1: "BAD_REQUEST",
	2: "FORBIDDEN",
	3: "UNKNOWN_ERROR",
	4: "PAGE_NOT_FOUND",
	5: "COULD_NOT_DECODE",
	6: "COULD_NOT_CRAWL",
}
var CrawlerGetSiteInfoResponse_ErrorType_value = map[string]int32{
	"NONE":             0,
	"BAD_REQUEST":      1,
	"FORBIDDEN":        2,
	"UNKNOWN_ERROR":    3,
	"PAGE_NOT_FOUND":   4,
	"COULD_NOT_DECODE": 5,
	"COULD_NOT_CRAWL":  6,
}

func (x CrawlerGetSiteInfoResponse_ErrorType) String() string {
	return proto.EnumName(CrawlerGetSiteInfoResponse_ErrorType_name, int32(x))
}

type WebsiteInfo_WebsiteType int32

const (
	WebsiteInfo_UNKNOWN WebsiteInfo_WebsiteType = 0
	WebsiteInfo_WIKI    WebsiteInfo_WebsiteType = 1
	WebsiteInfo_FORUM   WebsiteInfo_WebsiteType = 2
)

var WebsiteInfo_WebsiteType_name = map[int32]string{
	0: "UNKNOWN",
	1: "WIKI",
	2: "FORUM",
}
var WebsiteInfo_WebsiteType_value = map[string]int32{
	"UNKNOWN": 0,
	"WIKI":    1,
	"FORUM":   2,
}

func (x WebsiteInfo_WebsiteType) String() string {
	return proto.EnumName(WebsiteInfo_WebsiteType_name, int32(x))
}

type RPCCrawlerGetSiteInfoRequest struct {
	Url string `protobuf:"bytes,1,opt,name=url" json:"url,omitempty"`
}

func (m *RPCCrawlerGetSiteInfoRequest) Reset()         { *m = RPCCrawlerGetSiteInfoRequest{} }
func (m *RPCCrawlerGetSiteInfoRequest) String() string { return proto.CompactTextString(m) }
func (*RPCCrawlerGetSiteInfoRequest) ProtoMessage()    {}

type RPCCrawlerGetSiteInfoResponse struct {
	Error    CrawlerGetSiteInfoResponse_ErrorType `protobuf:"varint,1,opt,name=error,enum=proto.CrawlerGetSiteInfoResponse_ErrorType" json:"error,omitempty"`
	SiteInfo *WebsiteInfo                         `protobuf:"bytes,2,opt,name=site_info" json:"site_info,omitempty"`
}

func (m *RPCCrawlerGetSiteInfoResponse) Reset()         { *m = RPCCrawlerGetSiteInfoResponse{} }
func (m *RPCCrawlerGetSiteInfoResponse) String() string { return proto.CompactTextString(m) }
func (*RPCCrawlerGetSiteInfoResponse) ProtoMessage()    {}

func (m *RPCCrawlerGetSiteInfoResponse) GetSiteInfo() *WebsiteInfo {
	if m != nil {
		return m.SiteInfo
	}
	return nil
}

type CrawlerGetSiteInfoResponse struct {
	Error    CrawlerGetSiteInfoResponse_ErrorType `protobuf:"varint,1,opt,name=error,enum=proto.CrawlerGetSiteInfoResponse_ErrorType" json:"error,omitempty"`
	SiteInfo *WebsiteInfo                         `protobuf:"bytes,2,opt,name=site_info" json:"site_info,omitempty"`
}

func (m *CrawlerGetSiteInfoResponse) Reset()         { *m = CrawlerGetSiteInfoResponse{} }
func (m *CrawlerGetSiteInfoResponse) String() string { return proto.CompactTextString(m) }
func (*CrawlerGetSiteInfoResponse) ProtoMessage()    {}

func (m *CrawlerGetSiteInfoResponse) GetSiteInfo() *WebsiteInfo {
	if m != nil {
		return m.SiteInfo
	}
	return nil
}

type WebsiteInfo struct {
	Url          string                  `protobuf:"bytes,1,opt,name=url" json:"url,omitempty"`
	CanonicalUrl string                  `protobuf:"bytes,2,opt,name=canonical_url" json:"canonical_url,omitempty"`
	Title        string                  `protobuf:"bytes,3,opt,name=title" json:"title,omitempty"`
	Description  string                  `protobuf:"bytes,4,opt,name=description" json:"description,omitempty"`
	Keywords     []string                `protobuf:"bytes,5,rep,name=keywords" json:"keywords,omitempty"`
	Language     string                  `protobuf:"bytes,6,opt,name=language" json:"language,omitempty"`
	SiteType     WebsiteInfo_WebsiteType `protobuf:"varint,7,opt,name=site_type,enum=proto.WebsiteInfo_WebsiteType" json:"site_type,omitempty"`
	Topic        string                  `protobuf:"bytes,8,opt,name=topic" json:"topic,omitempty"`
	Colors       *WebsiteColors          `protobuf:"bytes,9,opt,name=colors" json:"colors,omitempty"`
	ShortName    string                  `protobuf:"bytes,10,opt,name=short_name" json:"short_name,omitempty"`
	ImageUrl     string                  `protobuf:"bytes,11,opt,name=image_url" json:"image_url,omitempty"`
	IconUrl      string                  `protobuf:"bytes,12,opt,name=icon_url" json:"icon_url,omitempty"`
}

func (m *WebsiteInfo) Reset()         { *m = WebsiteInfo{} }
func (m *WebsiteInfo) String() string { return proto.CompactTextString(m) }
func (*WebsiteInfo) ProtoMessage()    {}

func (m *WebsiteInfo) GetColors() *WebsiteColors {
	if m != nil {
		return m.Colors
	}
	return nil
}

type WebsiteColors struct {
}

func (m *WebsiteColors) Reset()         { *m = WebsiteColors{} }
func (m *WebsiteColors) String() string { return proto.CompactTextString(m) }
func (*WebsiteColors) ProtoMessage()    {}

func init() {
	proto.RegisterEnum("proto.CrawlerGetSiteInfoResponse_ErrorType", CrawlerGetSiteInfoResponse_ErrorType_name, CrawlerGetSiteInfoResponse_ErrorType_value)
	proto.RegisterEnum("proto.WebsiteInfo_WebsiteType", WebsiteInfo_WebsiteType_name, WebsiteInfo_WebsiteType_value)
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// Client API for CrawlerService service

type CrawlerServiceClient interface {
	GetSiteInfo(ctx context.Context, in *RPCCrawlerGetSiteInfoRequest, opts ...grpc.CallOption) (*RPCCrawlerGetSiteInfoResponse, error)
}

type crawlerServiceClient struct {
	cc *grpc.ClientConn
}

func NewCrawlerServiceClient(cc *grpc.ClientConn) CrawlerServiceClient {
	return &crawlerServiceClient{cc}
}

func (c *crawlerServiceClient) GetSiteInfo(ctx context.Context, in *RPCCrawlerGetSiteInfoRequest, opts ...grpc.CallOption) (*RPCCrawlerGetSiteInfoResponse, error) {
	out := new(RPCCrawlerGetSiteInfoResponse)
	err := grpc.Invoke(ctx, "/proto.CrawlerService/GetSiteInfo", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// Server API for CrawlerService service

type CrawlerServiceServer interface {
	GetSiteInfo(context.Context, *RPCCrawlerGetSiteInfoRequest) (*RPCCrawlerGetSiteInfoResponse, error)
}

func RegisterCrawlerServiceServer(s *grpc.Server, srv CrawlerServiceServer) {
	s.RegisterService(&_CrawlerService_serviceDesc, srv)
}

func _CrawlerService_GetSiteInfo_Handler(srv interface{}, ctx context.Context, codec grpc.Codec, buf []byte) (interface{}, error) {
	in := new(RPCCrawlerGetSiteInfoRequest)
	if err := codec.Unmarshal(buf, in); err != nil {
		return nil, err
	}
	out, err := srv.(CrawlerServiceServer).GetSiteInfo(ctx, in)
	if err != nil {
		return nil, err
	}
	return out, nil
}

var _CrawlerService_serviceDesc = grpc.ServiceDesc{
	ServiceName: "proto.CrawlerService",
	HandlerType: (*CrawlerServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "GetSiteInfo",
			Handler:    _CrawlerService_GetSiteInfo_Handler,
		},
	},
	Streams: []grpc.StreamDesc{},
}
